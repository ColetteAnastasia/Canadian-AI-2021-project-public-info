{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Original Mycode cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVtRsr_4o8E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d3b7d518-9a7b-4c9b-a71e-69415eba06ee"
      },
      "source": [
        "  '''\n",
        "keras_mnist_cnn_val.py\n",
        "\n",
        "Trains a convolution neural network on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs when using 60,000 train examples\n",
        "(and still a lot of margin for parameter tuning).\n",
        "Slow on a CPU, but only 16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set the seed value of the random number generator\n",
        "random_seed = 2\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "#print(tf.VERSION)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "print(\"The enviriment is ready.\")"
      ],
      "execution_count": 706,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0-tf\n",
            "The enviriment is ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJDYrktD4box",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "26f45029-e3a6-4f48-e83c-e4e030b92f21"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 1500\n",
        "all_sample = 50\n",
        "validation_num = int (all_sample / 5)\n",
        "train_ex = validation_num * 4\n",
        "\n",
        "\n",
        "''' Load the data in, choose the number of training, val, test\n",
        "    examples we want, and reshape the x data to the\n",
        "    correct shape (28x28x1). '''\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "shuffle_index  = [x for x in range(28*28)]\n",
        "random.shuffle(shuffle_index)\n",
        "print(x_train.shape)\n",
        "\n",
        "import random\n",
        "thisrange = 50000 - train_ex - 1 - 5000\n",
        "randnum = random.randint(0,thisrange)\n",
        "print(randnum)\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "y_tune  = tf.keras.utils.to_categorical(y_train[60000-validation_num-randnum:60000-randnum], num_classes)\n",
        "y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "for i in range(10):\n",
        "    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n",
        "    # no sense in showing labels if they don't match the letter\n",
        "    hot_index = np.argmax(y_test[i])\n",
        "    subplt.set_title(hot_index)\n",
        "    subplt.axis('off')\n",
        "    letter = x_test[i]\n",
        "    subplt.matshow(np.reshape(letter, [28, 28]))\n",
        "    plt.draw()\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "#print(x_train.shape, y_train.shape)\n",
        "#========================================================================\n",
        "#for i in range(len(x_train)):\n",
        "#    this_x_train = x_train[i]\n",
        "#    for j in range(len(x_train[i])):\n",
        "#        x_train[i][j]=this_x_train[shuffle_index[j]]\n",
        "#========================================================================\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_tune = x_train[60000-validation_num-randnum:60000-randnum]\n",
        "\n",
        "\n",
        "#x_train = x_train[randnum:train_ex+randnum]\n",
        "#y_train = tf.keras.utils.to_categorical(y_train[randnum:train_ex+randnum], num_classes)\n",
        "#=======================\n",
        "test_image = x_train[randnum:train_ex+randnum+5000].tolist()\n",
        "test_label = y_train[randnum:train_ex+randnum+5000].tolist()\n",
        "\n",
        "training_image = []\n",
        "training_label = []\n",
        "magic_num = train_ex/10\n",
        "count_0 = 0\n",
        "count_1 = 0\n",
        "count_2 = 0\n",
        "count_3 = 0\n",
        "count_4 = 0\n",
        "count_5 = 0\n",
        "count_6 = 0\n",
        "count_7 = 0\n",
        "count_8 = 0\n",
        "count_9 = 0\n",
        "total = 0\n",
        "for index, val in enumerate(test_label):\n",
        "    if (val==0) and (count_0 < magic_num):\n",
        "        count_0 = count_0 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==1 and count_1 < magic_num:\n",
        "        count_1 = count_1 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==2 and count_2 < magic_num:\n",
        "        count_2 = count_2 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==3 and count_3 < magic_num:\n",
        "        count_3 = count_3 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==4 and count_4 < magic_num:\n",
        "        count_4 = count_4 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==5 and count_5 < magic_num:\n",
        "        count_5 = count_5 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==6 and count_6 < magic_num:\n",
        "        count_6 = count_6 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==7 and count_7 < magic_num:\n",
        "        count_7 = count_7 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==8 and count_8 < magic_num:\n",
        "        count_8 = count_8 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==9 and count_9 < magic_num:\n",
        "        count_9 = count_9 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    if total == train_ex:\n",
        "        break\n",
        "x_train = np.array(training_image)\n",
        "y_train = np.array(tf.keras.utils.to_categorical(training_label, num_classes))\n",
        "#==============================\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "#========================================================================\n",
        "#print(x_test.shape,y_test.shape)\n",
        "#for i in range(len(x_test)):\n",
        "#    this_x_test = x_test[i]\n",
        "#    for j in range(len(x_test[i])):\n",
        "#        x_test[i][j]=this_x_test[shuffle_index[j]]\n",
        "#========================================================================\n",
        "\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_tune = x_tune.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_tune /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "\n",
        "\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_tune.shape, 'tune samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "print(y_train.shape, 'train targets')\n",
        "print(y_tune.shape, 'tune targets')\n",
        "print(y_test.shape, 'test targets')\n",
        "\n"
      ],
      "execution_count": 707,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "12109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(40, 28, 28, 1) train samples\n",
            "(10, 28, 28, 1) tune samples\n",
            "(10000, 28, 28, 1) test samples\n",
            "(40, 10) train targets\n",
            "(10, 10) tune targets\n",
            "(10000, 10) test targets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcm-54Q35El3",
        "colab_type": "text"
      },
      "source": [
        "#Step 2 - Configure the neural network architecture (graph) \n",
        "Keras follows the layers principle, where each network layer\n",
        "is independent and can be stacked and merged together.\n",
        "The Sequential model assumes that there is one long\n",
        "stack, with no branching.\n",
        "\n",
        "Typically, you will place a convolution layer, followed by maxpooling layer, followed by a dropout layer.  Combined these are sometimes referred to as convolutin stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLnzHHhQ46dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "cd568c47-9bfd-4280-c2b5-3e5b23cdff54"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "filters gives us the number of filters in the layer,the\n",
        "more filters we have, the more information we can learn\n",
        "\n",
        "kernel_size is the size of the convolution filter\n",
        "\n",
        "activation is the activation function on each node,\n",
        "we use relu, could also use sigmoid\n",
        "\n",
        "input_shape is the shape of the image. We reshaped\n",
        "the data above to get it in the right shape. The 1\n",
        "represents a grayscale image. If you had a colour\n",
        "image (RGB), the last dimension would be 3.\n",
        "\"\"\"\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "\n",
        "\n",
        "#model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
        "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(layers.Dropout(0.25))\n",
        "\n",
        "\"\"\" MaxPooling takes an NxM rectangle and find the maxiumum\n",
        "value in that square, and discards the rest. Since we are\n",
        "doing 2x2 pooling, it has the effect of halving the height\n",
        "and width of the image. \"\"\"\n",
        "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Set a random 25% of nodes to 0 to prevent overfitting\n",
        "#model.add(layers.Dropout(0.25))\n",
        "\n",
        "\"\"\" Add a second conv layer \n",
        "Note we don't need to give the shape between the first and\n",
        "second layer, Keras figures that out for us. \"\"\"\n",
        "model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Transform the 6x6x32 values to a flat 1152\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add an additonal hidden layer of dense nodes\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Finish with 10 softmax output nodes\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()   # Show a summary of the network architecture\n",
        "\n"
      ],
      "execution_count": 708,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_141\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_282 (Conv2D)          (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_283 (Conv2D)          (None, 25, 25, 16)        4112      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_141 (MaxPoolin (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_282 (Dropout)        (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_141 (Flatten)        (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_282 (Dense)            (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_283 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_283 (Dense)            (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 301,082\n",
            "Trainable params: 301,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8A0nKQv6UGc",
        "colab_type": "text"
      },
      "source": [
        "#Step 3 - Compile the model and fit the data to it\n",
        "The code for compiling two learning algorithms are provided to demostrate the variety of approaches that can be used to train networks.   \n",
        "The first uses the Adadelta Gradient Descent algorithm and does not use a validation set to prevent overfitting. \n",
        "The second uses the Stochastic Gradient Descent algorithm with momentum and a validation set to prevent overfitting.\n",
        "Both methods use the categorical cross-entropy loss function, which works well with the softmax activation output nodes. \n",
        "Using comments you can select the algorithm you wish to compile. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP7PGIeW6SEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c712b2c6-c0cb-472f-d3e1-fa2959830668"
      },
      "source": [
        "'''\n",
        "#############\n",
        "# Adadelta Gradient Descent without use of validation set \n",
        "# to prevent overfitting\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "#\n",
        "#############\n",
        "'''\n",
        "\n",
        "#############\n",
        "# Stochastic Gradient Descent with momentum and a validation set \n",
        "# to prevent overfitting\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.0025, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "#              optimizer=sgd,\n",
        "#              optimizer=tf.keras.optimizers.Adadelta(),\n",
        "              optimizer=tf.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Configure early stopping using validation accuracy from tune partition  \n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                   patience=100,  # epochs to wait after min loss\n",
        "                   verbose=1, \n",
        "                   restore_best_weights=True) # restore the best weights\n",
        "\n",
        "# The history structure keeps tabs on what happened during the session\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_tune, y_tune),\n",
        "          callbacks=[es])\n",
        "#\n",
        "#############\n",
        "\n"
      ],
      "execution_count": 709,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 2.2911 - accuracy: 0.1250 - val_loss: 2.2776 - val_accuracy: 0.1000\n",
            "Epoch 2/1500\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2210 - accuracy: 0.2750 - val_loss: 2.2259 - val_accuracy: 0.2000\n",
            "Epoch 3/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1961 - accuracy: 0.2500 - val_loss: 2.1674 - val_accuracy: 0.3000\n",
            "Epoch 4/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1429 - accuracy: 0.2500 - val_loss: 2.0684 - val_accuracy: 0.4000\n",
            "Epoch 5/1500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9949 - accuracy: 0.5000 - val_loss: 1.9290 - val_accuracy: 0.7000\n",
            "Epoch 6/1500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9023 - accuracy: 0.4000 - val_loss: 1.7378 - val_accuracy: 0.7000\n",
            "Epoch 7/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7286 - accuracy: 0.5000 - val_loss: 1.5650 - val_accuracy: 0.7000\n",
            "Epoch 8/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5173 - accuracy: 0.5250 - val_loss: 1.6446 - val_accuracy: 0.2000\n",
            "Epoch 9/1500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.5357 - accuracy: 0.5250 - val_loss: 1.3780 - val_accuracy: 0.6000\n",
            "Epoch 10/1500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4058 - accuracy: 0.6750 - val_loss: 1.2883 - val_accuracy: 0.6000\n",
            "Epoch 11/1500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8440 - accuracy: 0.8000 - val_loss: 1.0994 - val_accuracy: 0.8000\n",
            "Epoch 12/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.0253 - accuracy: 0.7250 - val_loss: 1.4737 - val_accuracy: 0.4000\n",
            "Epoch 13/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.9951 - accuracy: 0.7250 - val_loss: 1.0545 - val_accuracy: 0.6000\n",
            "Epoch 14/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7121 - accuracy: 0.8000 - val_loss: 1.2244 - val_accuracy: 0.4000\n",
            "Epoch 15/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8122 - accuracy: 0.7250 - val_loss: 1.2791 - val_accuracy: 0.7000\n",
            "Epoch 16/1500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7403 - accuracy: 0.8250 - val_loss: 1.0648 - val_accuracy: 0.6000\n",
            "Epoch 17/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6021 - accuracy: 0.7750 - val_loss: 1.2375 - val_accuracy: 0.5000\n",
            "Epoch 18/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5827 - accuracy: 0.8250 - val_loss: 0.8819 - val_accuracy: 0.7000\n",
            "Epoch 19/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6772 - accuracy: 0.7250 - val_loss: 1.4691 - val_accuracy: 0.6000\n",
            "Epoch 20/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5638 - accuracy: 0.8000 - val_loss: 0.7771 - val_accuracy: 0.8000\n",
            "Epoch 21/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3425 - accuracy: 0.9750 - val_loss: 0.8317 - val_accuracy: 0.8000\n",
            "Epoch 22/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2235 - accuracy: 0.9250 - val_loss: 0.9651 - val_accuracy: 0.7000\n",
            "Epoch 23/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2251 - accuracy: 0.9750 - val_loss: 0.7686 - val_accuracy: 0.8000\n",
            "Epoch 24/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1897 - accuracy: 0.9750 - val_loss: 0.9025 - val_accuracy: 0.8000\n",
            "Epoch 25/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3312 - accuracy: 0.9000 - val_loss: 0.6333 - val_accuracy: 0.9000\n",
            "Epoch 26/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2667 - accuracy: 0.8750 - val_loss: 0.7485 - val_accuracy: 0.8000\n",
            "Epoch 27/1500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1868 - accuracy: 0.9000 - val_loss: 0.9454 - val_accuracy: 0.8000\n",
            "Epoch 28/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8000\n",
            "Epoch 29/1500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1316 - accuracy: 0.9750 - val_loss: 0.9852 - val_accuracy: 0.8000\n",
            "Epoch 30/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1223 - accuracy: 0.9750 - val_loss: 0.9248 - val_accuracy: 0.7000\n",
            "Epoch 31/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1572 - accuracy: 0.9500 - val_loss: 0.9857 - val_accuracy: 0.8000\n",
            "Epoch 32/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1249 - accuracy: 0.9750 - val_loss: 0.8674 - val_accuracy: 0.8000\n",
            "Epoch 33/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1305 - accuracy: 0.9500 - val_loss: 0.8489 - val_accuracy: 0.8000\n",
            "Epoch 34/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.8255 - val_accuracy: 0.8000\n",
            "Epoch 35/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1216 - accuracy: 0.9250 - val_loss: 0.7455 - val_accuracy: 0.7000\n",
            "Epoch 36/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.8000\n",
            "Epoch 37/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.8000\n",
            "Epoch 38/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1044 - accuracy: 0.9750 - val_loss: 0.6056 - val_accuracy: 0.9000\n",
            "Epoch 39/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1787 - accuracy: 0.9500 - val_loss: 1.0635 - val_accuracy: 0.8000\n",
            "Epoch 40/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0832 - accuracy: 0.9750 - val_loss: 0.8112 - val_accuracy: 0.9000\n",
            "Epoch 41/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0945 - accuracy: 0.9750 - val_loss: 0.8082 - val_accuracy: 0.8000\n",
            "Epoch 42/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.7940 - val_accuracy: 0.8000\n",
            "Epoch 43/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1727 - accuracy: 0.9250 - val_loss: 1.1158 - val_accuracy: 0.8000\n",
            "Epoch 44/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1233 - accuracy: 0.9500 - val_loss: 0.8164 - val_accuracy: 0.8000\n",
            "Epoch 45/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.8449 - val_accuracy: 0.8000\n",
            "Epoch 46/1500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0959 - accuracy: 0.9750 - val_loss: 0.7070 - val_accuracy: 0.8000\n",
            "Epoch 47/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0647 - accuracy: 0.9750 - val_loss: 0.6757 - val_accuracy: 0.8000\n",
            "Epoch 48/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8000\n",
            "Epoch 49/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8000\n",
            "Epoch 50/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8000\n",
            "Epoch 51/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8000\n",
            "Epoch 52/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8000\n",
            "Epoch 53/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8000\n",
            "Epoch 54/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.8000\n",
            "Epoch 55/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.8000\n",
            "Epoch 56/1500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 0.8000\n",
            "Epoch 57/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.8000\n",
            "Epoch 58/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.8000\n",
            "Epoch 59/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.8985 - val_accuracy: 0.8000\n",
            "Epoch 60/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.8000\n",
            "Epoch 61/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.8000\n",
            "Epoch 62/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.8000\n",
            "Epoch 63/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.8000\n",
            "Epoch 64/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.8000\n",
            "Epoch 65/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0446 - accuracy: 0.9750 - val_loss: 0.9966 - val_accuracy: 0.8000\n",
            "Epoch 66/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.9882 - val_accuracy: 0.8000\n",
            "Epoch 67/1500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.8000\n",
            "Epoch 68/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.0292 - val_accuracy: 0.8000\n",
            "Epoch 69/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0309 - accuracy: 0.9750 - val_loss: 0.9543 - val_accuracy: 0.8000\n",
            "Epoch 70/1500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.8000\n",
            "Epoch 71/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.9675 - val_accuracy: 0.8000\n",
            "Epoch 72/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.8000\n",
            "Epoch 73/1500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0438 - accuracy: 0.9750 - val_loss: 0.9659 - val_accuracy: 0.8000\n",
            "Epoch 74/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.8000\n",
            "Epoch 75/1500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.0430 - val_accuracy: 0.8000\n",
            "Epoch 76/1500\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0198 - val_accuracy: 0.8000\n",
            "Epoch 77/1500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.8952 - val_accuracy: 0.8000\n",
            "Epoch 78/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0380 - accuracy: 0.9750 - val_loss: 0.9846 - val_accuracy: 0.8000\n",
            "Epoch 79/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.8000\n",
            "Epoch 80/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.8000\n",
            "Epoch 81/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.8000\n",
            "Epoch 82/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.8000\n",
            "Epoch 83/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0984 - accuracy: 0.9750 - val_loss: 1.0055 - val_accuracy: 0.8000\n",
            "Epoch 84/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0456 - accuracy: 0.9750 - val_loss: 0.9852 - val_accuracy: 0.8000\n",
            "Epoch 85/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.8000\n",
            "Epoch 86/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0404 - accuracy: 0.9750 - val_loss: 0.8495 - val_accuracy: 0.8000\n",
            "Epoch 87/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.8000\n",
            "Epoch 88/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0568 - accuracy: 0.9750 - val_loss: 0.8883 - val_accuracy: 0.8000\n",
            "Epoch 89/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.8000\n",
            "Epoch 90/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8000\n",
            "Epoch 91/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0268 - accuracy: 0.9750 - val_loss: 1.1056 - val_accuracy: 0.7000\n",
            "Epoch 92/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.0769 - val_accuracy: 0.7000\n",
            "Epoch 93/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.7000\n",
            "Epoch 94/1500\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.7000\n",
            "Epoch 95/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.8000\n",
            "Epoch 96/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.8000\n",
            "Epoch 97/1500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.8000\n",
            "Epoch 98/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.8000\n",
            "Epoch 99/1500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.8000\n",
            "Epoch 100/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1346 - val_accuracy: 0.8000\n",
            "Epoch 101/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.8000\n",
            "Epoch 102/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0288 - accuracy: 0.9750 - val_loss: 1.2962 - val_accuracy: 0.7000\n",
            "Epoch 103/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2513 - val_accuracy: 0.7000\n",
            "Epoch 104/1500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1459 - val_accuracy: 0.8000\n",
            "Epoch 105/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.8000\n",
            "Epoch 106/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0293 - accuracy: 0.9750 - val_loss: 0.8187 - val_accuracy: 0.8000\n",
            "Epoch 107/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.8610 - val_accuracy: 0.8000\n",
            "Epoch 108/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.9651 - val_accuracy: 0.8000\n",
            "Epoch 109/1500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8000\n",
            "Epoch 110/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9482 - val_accuracy: 0.8000\n",
            "Epoch 111/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9565 - val_accuracy: 0.8000\n",
            "Epoch 112/1500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9719 - val_accuracy: 0.8000\n",
            "Epoch 113/1500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.8000\n",
            "Epoch 114/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.8000\n",
            "Epoch 115/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.8000\n",
            "Epoch 116/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0432 - accuracy: 0.9750 - val_loss: 0.8965 - val_accuracy: 0.8000\n",
            "Epoch 117/1500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.9234 - val_accuracy: 0.8000\n",
            "Epoch 118/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9161 - val_accuracy: 0.8000\n",
            "Epoch 119/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8000\n",
            "Epoch 120/1500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.8000\n",
            "Epoch 121/1500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.1863e-04 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.8000\n",
            "Epoch 122/1500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0266 - accuracy: 0.9750 - val_loss: 0.9937 - val_accuracy: 0.8000\n",
            "Epoch 123/1500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.8000\n",
            "Epoch 124/1500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.8000\n",
            "Epoch 125/1500\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9750Restoring model weights from the end of the best epoch.\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0459 - accuracy: 0.9750 - val_loss: 0.8983 - val_accuracy: 0.8000\n",
            "Epoch 00125: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6_xZcGj7hhK",
        "colab_type": "text"
      },
      "source": [
        "#Step 4 - Evaluate the model on the test set and print the results.\n",
        "Pass the independent test data through the trained model and compute the test set cross-entropy  and test classification accuracy.\n",
        "For the first ten examples in the test set show us the examples and the associated network predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnrQvnpf7gcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "b97fef9b-ecd0-4115-b235-7b6655a830b0"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "predictions = model.predict(x_test, verbose=0)\n",
        "for i in range(10):\n",
        "    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n",
        "    # no sense in showing labels if they don't match the letter\n",
        "    hot_index = np.argmax(predictions[i])\n",
        "    subplt.set_title('P:{0}'.format(hot_index))\n",
        "    subplt.axis('off')\n",
        "    letter = x_test[i]\n",
        "    subplt.matshow(np.reshape(letter, [28, 28]))\n",
        "    plt.draw()\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.ylabel('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "# save plot to file\n",
        "#filename = sys.argv[0].split('/')[-1]\n",
        "#pyplot.savefig(filename + '_plot.png')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 710,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.0571234226226807\n",
            "Test accuracy: 0.6603000164031982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}