{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mycode cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVtRsr_4o8E9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "266b5dcc-9efe-4653-bd88-6d4911d46a18"
      },
      "source": [
        "  '''\n",
        "keras_mnist_cnn_val.py\n",
        "\n",
        "Trains a convolution neural network on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs when using 60,000 train examples\n",
        "(and still a lot of margin for parameter tuning).\n",
        "Slow on a CPU, but only 16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Set the seed value of the random number generator\n",
        "random_seed = 2\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "#print(tf.VERSION)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "print(\"The enviriment is ready.\")"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0-tf\n",
            "The enviriment is ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJDYrktD4box",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "9a508dbd-f8f4-47fe-9af7-e3584dce92b7"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 1500\n",
        "all_sample = 10000\n",
        "validation_num = int (all_sample / 5)\n",
        "train_ex = validation_num * 4\n",
        "\n",
        "\n",
        "''' Load the data in, choose the number of training, val, test\n",
        "    examples we want, and reshape the x data to the\n",
        "    correct shape (28x28x1). '''\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "shuffle_index  = [x for x in range(28*28)]\n",
        "random.shuffle(shuffle_index)\n",
        "print(x_train.shape)\n",
        "\n",
        "import random\n",
        "thisrange = 50000 - train_ex - 1 - 5000\n",
        "randnum = random.randint(0,thisrange)\n",
        "print(randnum)\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "y_tune  = tf.keras.utils.to_categorical(y_train[60000-validation_num-randnum:60000-randnum], num_classes)\n",
        "y_test  = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "for i in range(10):\n",
        "    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n",
        "    # no sense in showing labels if they don't match the letter\n",
        "    hot_index = np.argmax(y_test[i])\n",
        "    subplt.set_title(hot_index)\n",
        "    subplt.axis('off')\n",
        "    letter = x_test[i]\n",
        "    subplt.matshow(np.reshape(letter, [28, 28]))\n",
        "    plt.draw()\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "#print(x_train.shape, y_train.shape)\n",
        "#========================================================================\n",
        "for i in range(len(x_train)):\n",
        "    this_x_train = x_train[i]\n",
        "    for j in range(len(x_train[i])):\n",
        "        x_train[i][j]=this_x_train[shuffle_index[j]]\n",
        "#========================================================================\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_tune = x_train[60000-validation_num-randnum:60000-randnum]\n",
        "\n",
        "\n",
        "#x_train = x_train[randnum:train_ex+randnum]\n",
        "#y_train = tf.keras.utils.to_categorical(y_train[randnum:train_ex+randnum], num_classes)\n",
        "#=======================\n",
        "test_image = x_train[randnum:train_ex+randnum+5000].tolist()\n",
        "test_label = y_train[randnum:train_ex+randnum+5000].tolist()\n",
        "\n",
        "training_image = []\n",
        "training_label = []\n",
        "magic_num = train_ex/10\n",
        "count_0 = 0\n",
        "count_1 = 0\n",
        "count_2 = 0\n",
        "count_3 = 0\n",
        "count_4 = 0\n",
        "count_5 = 0\n",
        "count_6 = 0\n",
        "count_7 = 0\n",
        "count_8 = 0\n",
        "count_9 = 0\n",
        "total = 0\n",
        "for index, val in enumerate(test_label):\n",
        "    if (val==0) and (count_0 < magic_num):\n",
        "        count_0 = count_0 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==1 and count_1 < magic_num:\n",
        "        count_1 = count_1 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==2 and count_2 < magic_num:\n",
        "        count_2 = count_2 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==3 and count_3 < magic_num:\n",
        "        count_3 = count_3 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==4 and count_4 < magic_num:\n",
        "        count_4 = count_4 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==5 and count_5 < magic_num:\n",
        "        count_5 = count_5 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==6 and count_6 < magic_num:\n",
        "        count_6 = count_6 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==7 and count_7 < magic_num:\n",
        "        count_7 = count_7 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==8 and count_8 < magic_num:\n",
        "        count_8 = count_8 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    elif val==9 and count_9 < magic_num:\n",
        "        count_9 = count_9 + 1\n",
        "        total = total + 1\n",
        "        training_image.append(test_image[index])\n",
        "        training_label.append(val)\n",
        "    if total == train_ex:\n",
        "        break\n",
        "x_train = np.array(training_image)\n",
        "y_train = np.array(tf.keras.utils.to_categorical(training_label, num_classes))\n",
        "#==============================\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "#========================================================================\n",
        "#print(x_test.shape,y_test.shape)\n",
        "for i in range(len(x_test)):\n",
        "    this_x_test = x_test[i]\n",
        "    for j in range(len(x_test[i])):\n",
        "        x_test[i][j]=this_x_test[shuffle_index[j]]\n",
        "#========================================================================\n",
        "\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_tune = x_tune.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_tune /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "\n",
        "\n",
        "print(x_train.shape, 'train samples')\n",
        "print(x_tune.shape, 'tune samples')\n",
        "print(x_test.shape, 'test samples')\n",
        "print(y_train.shape, 'train targets')\n",
        "print(y_tune.shape, 'tune targets')\n",
        "print(y_test.shape, 'test targets')\n",
        "\n"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "26241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(8000, 28, 28, 1) train samples\n",
            "(2000, 28, 28, 1) tune samples\n",
            "(10000, 28, 28, 1) test samples\n",
            "(8000, 10) train targets\n",
            "(2000, 10) tune targets\n",
            "(10000, 10) test targets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcm-54Q35El3",
        "colab_type": "text"
      },
      "source": [
        "#Step 2 - Configure the neural network architecture (graph) \n",
        "Keras follows the layers principle, where each network layer\n",
        "is independent and can be stacked and merged together.\n",
        "The Sequential model assumes that there is one long\n",
        "stack, with no branching.\n",
        "\n",
        "Typically, you will place a convolution layer, followed by maxpooling layer, followed by a dropout layer.  Combined these are sometimes referred to as convolutin stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLnzHHhQ46dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "2cbdb8e0-9544-4505-bfe0-fe747ff22568"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "filters gives us the number of filters in the layer,the\n",
        "more filters we have, the more information we can learn\n",
        "\n",
        "kernel_size is the size of the convolution filter\n",
        "\n",
        "activation is the activation function on each node,\n",
        "we use relu, could also use sigmoid\n",
        "\n",
        "input_shape is the shape of the image. We reshaped\n",
        "the data above to get it in the right shape. The 1\n",
        "represents a grayscale image. If you had a colour\n",
        "image (RGB), the last dimension would be 3.\n",
        "\"\"\"\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1)))\n",
        "\n",
        "\n",
        "#model.add(layers.Conv2D(64, (2, 2), activation='relu'))\n",
        "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(layers.Dropout(0.25))\n",
        "\n",
        "\"\"\" MaxPooling takes an NxM rectangle and find the maxiumum\n",
        "value in that square, and discards the rest. Since we are\n",
        "doing 2x2 pooling, it has the effect of halving the height\n",
        "and width of the image. \"\"\"\n",
        "#model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Set a random 25% of nodes to 0 to prevent overfitting\n",
        "#model.add(layers.Dropout(0.25))\n",
        "\n",
        "\"\"\" Add a second conv layer \n",
        "Note we don't need to give the shape between the first and\n",
        "second layer, Keras figures that out for us. \"\"\"\n",
        "model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# Transform the 6x6x32 values to a flat 1152\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Add an additonal hidden layer of dense nodes\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Finish with 10 softmax output nodes\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()   # Show a summary of the network architecture\n",
        "\n"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_162 (Conv2D)          (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 25, 25, 16)        4112      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_81 (MaxPooling (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_162 (Dropout)        (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_81 (Flatten)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_163 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 301,082\n",
            "Trainable params: 301,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8A0nKQv6UGc",
        "colab_type": "text"
      },
      "source": [
        "#Step 3 - Compile the model and fit the data to it\n",
        "The code for compiling two learning algorithms are provided to demostrate the variety of approaches that can be used to train networks.   \n",
        "The first uses the Adadelta Gradient Descent algorithm and does not use a validation set to prevent overfitting. \n",
        "The second uses the Stochastic Gradient Descent algorithm with momentum and a validation set to prevent overfitting.\n",
        "Both methods use the categorical cross-entropy loss function, which works well with the softmax activation output nodes. \n",
        "Using comments you can select the algorithm you wish to compile. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP7PGIeW6SEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8c24b90-0e24-49ca-e829-9fbbaed75a8a"
      },
      "source": [
        "'''\n",
        "#############\n",
        "# Adadelta Gradient Descent without use of validation set \n",
        "# to prevent overfitting\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "#\n",
        "#############\n",
        "'''\n",
        "\n",
        "#############\n",
        "# Stochastic Gradient Descent with momentum and a validation set \n",
        "# to prevent overfitting\n",
        "\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.0025, momentum=0.9)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "#              optimizer=sgd,\n",
        "#              optimizer=tf.keras.optimizers.Adadelta(),\n",
        "              optimizer=tf.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Configure early stopping using validation accuracy from tune partition  \n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                   patience=100,  # epochs to wait after min loss\n",
        "                   verbose=1, \n",
        "                   restore_best_weights=True) # restore the best weights\n",
        "\n",
        "# The history structure keeps tabs on what happened during the session\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_tune, y_tune),\n",
        "          callbacks=[es])\n",
        "#\n",
        "#############\n",
        "\n"
      ],
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1500\n",
            "63/63 [==============================] - 1s 9ms/step - loss: 1.4435 - accuracy: 0.5023 - val_loss: 0.6176 - val_accuracy: 0.8105\n",
            "Epoch 2/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.6751 - accuracy: 0.7778 - val_loss: 0.3701 - val_accuracy: 0.8915\n",
            "Epoch 3/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4948 - accuracy: 0.8391 - val_loss: 0.2823 - val_accuracy: 0.9195\n",
            "Epoch 4/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8696 - val_loss: 0.2156 - val_accuracy: 0.9395\n",
            "Epoch 5/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.3434 - accuracy: 0.8929 - val_loss: 0.1732 - val_accuracy: 0.9510\n",
            "Epoch 6/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.3109 - accuracy: 0.8995 - val_loss: 0.1514 - val_accuracy: 0.9560\n",
            "Epoch 7/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2704 - accuracy: 0.9155 - val_loss: 0.1290 - val_accuracy: 0.9685\n",
            "Epoch 8/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2523 - accuracy: 0.9218 - val_loss: 0.1062 - val_accuracy: 0.9715\n",
            "Epoch 9/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2254 - accuracy: 0.9293 - val_loss: 0.0979 - val_accuracy: 0.9730\n",
            "Epoch 10/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.2075 - accuracy: 0.9331 - val_loss: 0.0878 - val_accuracy: 0.9770\n",
            "Epoch 11/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1839 - accuracy: 0.9392 - val_loss: 0.0745 - val_accuracy: 0.9810\n",
            "Epoch 12/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1846 - accuracy: 0.9433 - val_loss: 0.0609 - val_accuracy: 0.9830\n",
            "Epoch 13/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1601 - accuracy: 0.9460 - val_loss: 0.0680 - val_accuracy: 0.9835\n",
            "Epoch 14/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1481 - accuracy: 0.9509 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
            "Epoch 15/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1423 - accuracy: 0.9550 - val_loss: 0.0514 - val_accuracy: 0.9850\n",
            "Epoch 16/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1335 - accuracy: 0.9551 - val_loss: 0.0461 - val_accuracy: 0.9895\n",
            "Epoch 17/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9559 - val_loss: 0.0367 - val_accuracy: 0.9895\n",
            "Epoch 18/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1299 - accuracy: 0.9579 - val_loss: 0.0312 - val_accuracy: 0.9915\n",
            "Epoch 19/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1118 - accuracy: 0.9611 - val_loss: 0.0290 - val_accuracy: 0.9915\n",
            "Epoch 20/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.1112 - accuracy: 0.9639 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
            "Epoch 21/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0982 - accuracy: 0.9664 - val_loss: 0.0219 - val_accuracy: 0.9955\n",
            "Epoch 22/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 0.9663 - val_loss: 0.0214 - val_accuracy: 0.9960\n",
            "Epoch 23/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.0178 - val_accuracy: 0.9975\n",
            "Epoch 24/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0850 - accuracy: 0.9701 - val_loss: 0.0203 - val_accuracy: 0.9965\n",
            "Epoch 25/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0736 - accuracy: 0.9743 - val_loss: 0.0131 - val_accuracy: 0.9980\n",
            "Epoch 26/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9734 - val_loss: 0.0136 - val_accuracy: 0.9980\n",
            "Epoch 27/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9728 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
            "Epoch 28/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9755 - val_loss: 0.0136 - val_accuracy: 0.9980\n",
            "Epoch 29/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 0.0122 - val_accuracy: 0.9980\n",
            "Epoch 30/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 0.9776 - val_loss: 0.0108 - val_accuracy: 0.9990\n",
            "Epoch 31/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.0102 - val_accuracy: 0.9985\n",
            "Epoch 32/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9783 - val_loss: 0.0098 - val_accuracy: 0.9990\n",
            "Epoch 33/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9793 - val_loss: 0.0105 - val_accuracy: 0.9985\n",
            "Epoch 34/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9806 - val_loss: 0.0098 - val_accuracy: 0.9985\n",
            "Epoch 35/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 0.0098 - val_accuracy: 0.9985\n",
            "Epoch 36/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.0104 - val_accuracy: 0.9985\n",
            "Epoch 37/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0552 - accuracy: 0.9785 - val_loss: 0.0089 - val_accuracy: 0.9995\n",
            "Epoch 38/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9772 - val_loss: 0.0079 - val_accuracy: 0.9985\n",
            "Epoch 39/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 0.0094 - val_accuracy: 0.9990\n",
            "Epoch 40/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9801 - val_loss: 0.0085 - val_accuracy: 0.9995\n",
            "Epoch 41/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9835 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
            "Epoch 42/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9837 - val_loss: 0.0093 - val_accuracy: 0.9995\n",
            "Epoch 43/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
            "Epoch 44/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
            "Epoch 45/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
            "Epoch 46/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
            "Epoch 47/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.0079 - val_accuracy: 0.9990\n",
            "Epoch 48/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "Epoch 49/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 50/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
            "Epoch 51/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
            "Epoch 52/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 0.0073 - val_accuracy: 0.9990\n",
            "Epoch 53/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9851 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 54/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
            "Epoch 55/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
            "Epoch 56/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9876 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
            "Epoch 57/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9866 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
            "Epoch 58/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9876 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 59/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 60/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0355 - accuracy: 0.9876 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
            "Epoch 61/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
            "Epoch 62/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0060 - val_accuracy: 0.9995\n",
            "Epoch 63/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
            "Epoch 64/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
            "Epoch 65/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0084 - val_accuracy: 0.9995\n",
            "Epoch 66/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 67/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
            "Epoch 68/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
            "Epoch 69/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 70/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9854 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 71/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
            "Epoch 72/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
            "Epoch 73/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
            "Epoch 74/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 75/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 76/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
            "Epoch 77/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 0.9914 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
            "Epoch 78/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9911 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 79/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
            "Epoch 80/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
            "Epoch 81/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
            "Epoch 82/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
            "Epoch 83/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
            "Epoch 84/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
            "Epoch 85/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 86/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 87/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
            "Epoch 88/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 0.9915 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
            "Epoch 89/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
            "Epoch 90/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9912 - val_loss: 0.0084 - val_accuracy: 0.9995\n",
            "Epoch 91/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
            "Epoch 92/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9902 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
            "Epoch 93/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
            "Epoch 94/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
            "Epoch 95/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9927 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
            "Epoch 96/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 97/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
            "Epoch 98/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 99/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9912 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 100/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
            "Epoch 101/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 102/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
            "Epoch 103/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 0.9926 - val_loss: 0.0091 - val_accuracy: 0.9995\n",
            "Epoch 104/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.0082 - val_accuracy: 0.9995\n",
            "Epoch 105/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.0082 - val_accuracy: 0.9995\n",
            "Epoch 106/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
            "Epoch 107/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 108/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
            "Epoch 109/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
            "Epoch 110/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
            "Epoch 111/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
            "Epoch 112/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
            "Epoch 113/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 114/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
            "Epoch 115/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
            "Epoch 116/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9934 - val_loss: 0.0085 - val_accuracy: 0.9995\n",
            "Epoch 117/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.0091 - val_accuracy: 0.9995\n",
            "Epoch 118/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0094 - val_accuracy: 0.9995\n",
            "Epoch 119/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0086 - val_accuracy: 0.9995\n",
            "Epoch 120/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0090 - val_accuracy: 0.9995\n",
            "Epoch 121/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0085 - val_accuracy: 0.9995\n",
            "Epoch 122/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9919 - val_loss: 0.0093 - val_accuracy: 0.9995\n",
            "Epoch 123/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.0101 - val_accuracy: 0.9995\n",
            "Epoch 124/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0106 - val_accuracy: 0.9995\n",
            "Epoch 125/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0094 - val_accuracy: 0.9995\n",
            "Epoch 126/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0092 - val_accuracy: 0.9995\n",
            "Epoch 127/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0083 - val_accuracy: 0.9995\n",
            "Epoch 128/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.0096 - val_accuracy: 0.9995\n",
            "Epoch 129/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 0.0090 - val_accuracy: 0.9995\n",
            "Epoch 130/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0095 - val_accuracy: 0.9995\n",
            "Epoch 131/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 0.0094 - val_accuracy: 0.9995\n",
            "Epoch 132/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.0092 - val_accuracy: 0.9995\n",
            "Epoch 133/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.0095 - val_accuracy: 0.9995\n",
            "Epoch 134/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.0084 - val_accuracy: 0.9995\n",
            "Epoch 135/1500\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.0082 - val_accuracy: 0.9995\n",
            "Epoch 136/1500\n",
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
            "Epoch 137/1500\n",
            "58/63 [==========================>...] - ETA: 0s - loss: 0.0142 - accuracy: 0.9957Restoring model weights from the end of the best epoch.\n",
            "63/63 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
            "Epoch 00137: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6_xZcGj7hhK",
        "colab_type": "text"
      },
      "source": [
        "#Step 4 - Evaluate the model on the test set and print the results.\n",
        "Pass the independent test data through the trained model and compute the test set cross-entropy  and test classification accuracy.\n",
        "For the first ten examples in the test set show us the examples and the associated network predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnrQvnpf7gcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "cfe40c64-9a40-4ee3-8798-e8f614e451e6"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "predictions = model.predict(x_test, verbose=0)\n",
        "for i in range(10):\n",
        "    subplt = plt.subplot(int(i / 10) + 1, 10, i + 1)\n",
        "    # no sense in showing labels if they don't match the letter\n",
        "    hot_index = np.argmax(predictions[i])\n",
        "    subplt.set_title('P:{0}'.format(hot_index))\n",
        "    subplt.axis('off')\n",
        "    letter = x_test[i]\n",
        "    subplt.matshow(np.reshape(letter, [28, 28]))\n",
        "    plt.draw()\n",
        "    \n",
        "plt.show()\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.ylabel('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "# save plot to file\n",
        "#filename = sys.argv[0].split('/')[-1]\n",
        "#pyplot.savefig(filename + '_plot.png')\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.20975585281848907\n",
            "Test accuracy: 0.9483000040054321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}